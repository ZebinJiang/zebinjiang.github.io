<!DOCTYPE html>

<html class="fontawesome-i2svg-active fontawesome-i2svg-complete"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>LGGD</title>

  <style type="text/css">svg:not(:root).svg-inline--fa{overflow:visible}.svg-inline--fa{display:inline-block;font-size:inherit;height:1em;overflow:visible;vertical-align:-.125em}.svg-inline--fa.fa-lg{vertical-align:-.225em}.svg-inline--fa.fa-w-1{width:.0625em}.svg-inline--fa.fa-w-2{width:.125em}.svg-inline--fa.fa-w-3{width:.1875em}.svg-inline--fa.fa-w-4{width:.25em}.svg-inline--fa.fa-w-5{width:.3125em}.svg-inline--fa.fa-w-6{width:.375em}.svg-inline--fa.fa-w-7{width:.4375em}.svg-inline--fa.fa-w-8{width:.5em}.svg-inline--fa.fa-w-9{width:.5625em}.svg-inline--fa.fa-w-10{width:.625em}.svg-inline--fa.fa-w-11{width:.6875em}.svg-inline--fa.fa-w-12{width:.75em}.svg-inline--fa.fa-w-13{width:.8125em}.svg-inline--fa.fa-w-14{width:.875em}.svg-inline--fa.fa-w-15{width:.9375em}.svg-inline--fa.fa-w-16{width:1em}.svg-inline--fa.fa-w-17{width:1.0625em}.svg-inline--fa.fa-w-18{width:1.125em}.svg-inline--fa.fa-w-19{width:1.1875em}.svg-inline--fa.fa-w-20{width:1.25em}.svg-inline--fa.fa-pull-left{margin-right:.3em;width:auto}.svg-inline--fa.fa-pull-right{margin-left:.3em;width:auto}.svg-inline--fa.fa-border{height:1.5em}.svg-inline--fa.fa-li{width:2em}.svg-inline--fa.fa-fw{width:1.25em}.fa-layers svg.svg-inline--fa{bottom:0;left:0;margin:auto;position:absolute;right:0;top:0}.fa-layers{display:inline-block;height:1em;position:relative;text-align:center;vertical-align:-.125em;width:1em}.fa-layers svg.svg-inline--fa{-webkit-transform-origin:center center;transform-origin:center center}.fa-layers-counter,.fa-layers-text{display:inline-block;position:absolute;text-align:center}.fa-layers-text{left:50%;top:50%;-webkit-transform:translate(-50%,-50%);transform:translate(-50%,-50%);-webkit-transform-origin:center center;transform-origin:center center}.fa-layers-counter{background-color:#ff253a;border-radius:1em;-webkit-box-sizing:border-box;box-sizing:border-box;color:#fff;height:1.5em;line-height:1;max-width:5em;min-width:1.5em;overflow:hidden;padding:.25em;right:0;text-overflow:ellipsis;top:0;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:top right;transform-origin:top right}.fa-layers-bottom-right{bottom:0;right:0;top:auto;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:bottom right;transform-origin:bottom right}.fa-layers-bottom-left{bottom:0;left:0;right:auto;top:auto;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:bottom left;transform-origin:bottom left}.fa-layers-top-right{right:0;top:0;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:top right;transform-origin:top right}.fa-layers-top-left{left:0;right:auto;top:0;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:top left;transform-origin:top left}.fa-lg{font-size:1.3333333333em;line-height:.75em;vertical-align:-.0667em}.fa-xs{font-size:.75em}.fa-sm{font-size:.875em}.fa-1x{font-size:1em}.fa-2x{font-size:2em}.fa-3x{font-size:3em}.fa-4x{font-size:4em}.fa-5x{font-size:5em}.fa-6x{font-size:6em}.fa-7x{font-size:7em}.fa-8x{font-size:8em}.fa-9x{font-size:9em}.fa-10x{font-size:10em}.fa-fw{text-align:center;width:1.25em}.fa-ul{list-style-type:none;margin-left:2.5em;padding-left:0}.fa-ul>li{position:relative}.fa-li{left:-2em;position:absolute;text-align:center;width:2em;line-height:inherit}.fa-border{border:solid .08em #eee;border-radius:.1em;padding:.2em .25em .15em}.fa-pull-left{float:left}.fa-pull-right{float:right}.fa.fa-pull-left,.fab.fa-pull-left,.fal.fa-pull-left,.far.fa-pull-left,.fas.fa-pull-left{margin-right:.3em}.fa.fa-pull-right,.fab.fa-pull-right,.fal.fa-pull-right,.far.fa-pull-right,.fas.fa-pull-right{margin-left:.3em}.fa-spin{-webkit-animation:fa-spin 2s infinite linear;animation:fa-spin 2s infinite linear}.fa-pulse{-webkit-animation:fa-spin 1s infinite steps(8);animation:fa-spin 1s infinite steps(8)}@-webkit-keyframes fa-spin{0%{-webkit-transform:rotate(0);transform:rotate(0)}100%{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}@keyframes fa-spin{0%{-webkit-transform:rotate(0);transform:rotate(0)}100%{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}.fa-rotate-90{-webkit-transform:rotate(90deg);transform:rotate(90deg)}.fa-rotate-180{-webkit-transform:rotate(180deg);transform:rotate(180deg)}.fa-rotate-270{-webkit-transform:rotate(270deg);transform:rotate(270deg)}.fa-flip-horizontal{-webkit-transform:scale(-1,1);transform:scale(-1,1)}.fa-flip-vertical{-webkit-transform:scale(1,-1);transform:scale(1,-1)}.fa-flip-both,.fa-flip-horizontal.fa-flip-vertical{-webkit-transform:scale(-1,-1);transform:scale(-1,-1)}:root .fa-flip-both,:root .fa-flip-horizontal,:root .fa-flip-vertical,:root .fa-rotate-180,:root .fa-rotate-270,:root .fa-rotate-90{-webkit-filter:none;filter:none}.fa-stack{display:inline-block;height:2em;position:relative;width:2.5em}.fa-stack-1x,.fa-stack-2x{bottom:0;left:0;margin:auto;position:absolute;right:0;top:0}.svg-inline--fa.fa-stack-1x{height:1em;width:1.25em}.svg-inline--fa.fa-stack-2x{height:2em;width:2.5em}.fa-inverse{color:#fff}.sr-only{border:0;clip:rect(0,0,0,0);height:1px;margin:-1px;overflow:hidden;padding:0;position:absolute;width:1px}.sr-only-focusable:active,.sr-only-focusable:focus{clip:auto;height:auto;margin:0;overflow:visible;position:static;width:auto}.svg-inline--fa .fa-primary{fill:var(--fa-primary-color,currentColor);opacity:1;opacity:var(--fa-primary-opacity,1)}.svg-inline--fa .fa-secondary{fill:var(--fa-secondary-color,currentColor);opacity:.4;opacity:var(--fa-secondary-opacity,.4)}.svg-inline--fa.fa-swap-opacity .fa-primary{opacity:.4;opacity:var(--fa-secondary-opacity,.4)}.svg-inline--fa.fa-swap-opacity .fa-secondary{opacity:1;opacity:var(--fa-primary-opacity,1)}.svg-inline--fa mask .fa-primary,.svg-inline--fa mask .fa-secondary{fill:#000}.fad.fa-inverse{color:#fff}</style><link rel="stylesheet" href="./lggd/bulma.min.css">
  <link rel="stylesheet" href="./lggd/bulma-carousel.min.css">
  <link rel="stylesheet" href="./lggd/fontawesome.all.min.css">
  <!-- <link rel="stylesheet" href="./lggd/academicons.min.css"> -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./lggd/index.css">

  <script type="text/javascript" async="" src="./lggd/analytics.js"></script><script type="text/javascript" async="" src="./lggd/js"></script><script src="./lggd/jquery.min.js"></script>
  <script defer="" src="./lggd/fontawesome.all.min.js"></script>
  <script src="./lggd/bulma-carousel.min.js"></script>
  <script src="./lggd/index.js"></script>
<link rel="”preconnect”" href="https://www.timothybrooks.com/instruct-pix2pix/%E2%80%9Dhttps://www.google-analytics.com%E2%80%9D">
<script async="" src="./lggd/js(1)"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-146060534-1');
</script></head>

<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <!-- <h1 class="title is-1 publication-title" style="font-size: 44px;">Auto MC-Reward: Automated Dense</h1> -->
            <h2 class="title is-2 publication-title">Language-Guided Grasp Detection with Coarse-to-Fine Learning for Robotic Manipulation</h2>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="need to be filled" target="_blank">Zebin Jiang</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="need to be filled" target="_blank">Tianle Jin</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="need to be filled" target="_blank">Xiangtong Yao</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://www.ce.cit.tum.de/en/air/people/prof-dr-ing-habil-alois-knoll/" target="_blank">
                  Alois Knoll
                </a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://hucaofighting.github.io/" target="_blank">Hu Cao</a><sup>1,2*</sup>
              </span>
            </div>
            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Southeast University</span>&nbsp;&nbsp;&nbsp;
              <span class="author-block"><sup>2</sup>Technical University of Munich</span>&nbsp;&nbsp;&nbsp;
            </div>
            <p class="is-size-7 is-text-centered">
              <!-- <sup>*†</sup>Denotes equal contribution &nbsp;&nbsp;&nbsp;  -->
              <sup>*</sup>Indicates corresponding author
	      <br><br>
            </p>
            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2512.21065" class="external-link button is-normal is-rounded is-dark" target="_blank">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                   <!--  <span class="icon">
                      <svg class="svg-inline--fa fa-file-pdf fa-w-12" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="file-pdf" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512" data-fa-i2svg=""><path fill="currentColor" d="M181.9 256.1c-5-16-4.9-46.9-2-46.9 8.4 0 7.6 36.9 2 46.9zm-1.7 47.2c-7.7 20.2-17.3 43.3-28.4 62.7 18.3-7 39-17.2 62.9-21.9-12.7-9.6-24.9-23.4-34.5-40.8zM86.1 428.1c0 .8 13.2-5.4 34.9-40.2-6.7 6.3-29.1 24.5-34.9 40.2zM248 160h136v328c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V24C0 10.7 10.7 0 24 0h200v136c0 13.2 10.8 24 24 24zm-8 171.8c-20-12.2-33.3-29-42.7-53.8 4.5-18.5 11.6-46.6 6.2-64.2-4.7-29.4-42.4-26.5-47.8-6.8-5 18.3-.4 44.1 8.1 77-11.6 27.6-28.7 64.6-40.8 85.8-.1 0-.1.1-.2.1-27.1 13.9-73.6 44.5-54.5 68 5.6 6.9 16 10 21.5 10 17.9 0 35.7-18 61.1-61.8 25.8-8.5 54.1-19.1 79-23.2 21.7 11.8 47.1 19.5 64 19.5 29.2 0 31.2-32 19.7-43.4-13.9-13.6-54.3-9.7-73.6-7.2zM377 105L279 7c-4.5-4.5-10.6-7-17-7h-6v128h128v-6.1c0-6.3-2.5-12.4-7-16.9zm-74.1 255.3c4.1-2.7-2.5-11.9-42.8-9 37.1 15.8 42.8 9 42.8 9z"></path></svg>
                  </span> -->
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://github.com/ZebinJiang/LGGD" class="external-link button is-normal is-rounded is-dark" target="_blank">
                    <span class="icon">
                      <i class="fab fa-github "></i>
                    </span>
                    <!-- <span class="icon">
                      <svg class="svg-inline--fa fa-edit fa-w-18" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="edit" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512" data-fa-i2svg=""><path fill="currentColor" d="M402.6 83.2l90.2 90.2c3.8 3.8 3.8 10 0 13.8L274.4 405.6l-92.8 10.3c-12.4 1.4-22.9-9.1-21.5-21.5l10.3-92.8L388.8 83.2c3.8-3.8 10-3.8 13.8 0zm162-22.9l-48.8-48.8c-15.2-15.2-39.9-15.2-55.2 0l-35.4 35.4c-3.8 3.8-3.8 10 0 13.8l90.2 90.2c3.8 3.8 10 3.8 13.8 0l35.4-35.4c15.2-15.3 15.2-40 0-55.2zM384 346.2V448H64V128h229.8c3.2 0 6.2-1.3 8.5-3.5l40-40c7.6-7.6 2.2-20.5-8.5-20.5H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h352c26.5 0 48-21.5 48-48V306.2c0-10.7-12.9-16-20.5-8.5l-40 40c-2.2 2.3-3.5 5.3-3.5 8.5z"></path></svg>
                    </span> -->
                    <span>Code comming soon</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="" class="external-link button is-normal is-rounded is-dark" target="_blank">
                    <span class="icon">
                      <i class="fab fa-youtube "></i>
                    </span>
                    <!-- <span class="icon">
                      <svg class="svg-inline--fa fa-edit fa-w-18" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="edit" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512" data-fa-i2svg=""><path fill="currentColor" d="M402.6 83.2l90.2 90.2c3.8 3.8 3.8 10 0 13.8L274.4 405.6l-92.8 10.3c-12.4 1.4-22.9-9.1-21.5-21.5l10.3-92.8L388.8 83.2c3.8-3.8 10-3.8 13.8 0zm162-22.9l-48.8-48.8c-15.2-15.2-39.9-15.2-55.2 0l-35.4 35.4c-3.8 3.8-3.8 10 0 13.8l90.2 90.2c3.8 3.8 10 3.8 13.8 0l35.4-35.4c15.2-15.3 15.2-40 0-55.2zM384 346.2V448H64V128h229.8c3.2 0 6.2-1.3 8.5-3.5l40-40c7.6-7.6 2.2-20.5-8.5-20.5H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h352c26.5 0 48-21.5 48-48V306.2c0-10.7-12.9-16-20.5-8.5l-40 40c-2.2 2.3-3.5 5.3-3.5 8.5z"></path></svg>
                    </span> -->
                    <span>YouTube comming soon</span>
                  </a>
                </span>
            
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-8">
          <!-- <h2 class="title is-2">Framework</h2> -->
          <!-- <figure style="text-align: center;">
            <img id="teaser" height="100%" src="./lggd/Overview.png" alt="crop_ProblemV2" style="vertical-align: middle;">
            </figure> -->
            <figure style="text-align: center;">
              <img
                id="teaser"
                src="./lggd/Overview.png"
                alt="Overview"
                style="width: 85%; height: auto; vertical-align: middle;"
              >
            </figure>
          <div class="content has-text-justified">
            <p>
              Overview of our system: An RGB-D camera mounted
              on the robot's wrist captures visual data of objects to be
              grasped. Our proposed LGGD generates 4-DoF grasp poses
              based on the RGB image and language query during the inference process. These generated grasp poses are then utilized
              by the control module to plan and execute robot trajectories
              for pick-and-place tasks.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="section abstract-section">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-8">
          <h2 class="title is-2">Abstract</h2>
          <div class="content has-text-justified">
          <!-- <div class="content has-text-justified" style="color: #666;"></div> -->
            <p>
              Grasping is one of the most fundamental challenging capabilities in robotic manipulation, especially in unstructured, cluttered, and semantically diverse environments. Recent researches have increasingly explored language-guided manipulation, where robots not only perceive the scene but also interpret task-relevant natural language instructions. However, existing language-conditioned grasping methods typically rely on shallow fusion strategies, leading to limited semantic grounding and weak alignment between linguistic intent and visual grasp reasoning. In this work, we propose <strong>Language-Guided Grasp Detection (LGGD)</strong> with a <strong>coarse-to-fine learning</strong> paradigm for robotic manipulation. LGGD leverages CLIP-based visual and textual embeddings within a hierarchical cross-modal fusion pipeline, progressively injecting linguistic cues into the visual feature reconstruction process. This design enables fine-grained visual-semantic alignment and improves the feasibility of the predicted grasps with respect to task instructions. In addition, we introduce a language-conditioned dynamic convolution head (LDCH) that mixes multiple convolution experts based on sentence-level features, enabling instruction-adaptive coarse mask and grasp predictions. A final refinement module further enhances grasp consistency and robustness in complex scenes. Experiments on the OCID-VLG and Grasp-Anything++ datasets show that LGGD surpasses existing language-guided grasping methods, exhibiting strong generalization to unseen objects and diverse language queries. Moreover, deployment on a real robotic platform demonstrates the practical effectiveness of our approach in executing accurate, instruction-conditioned grasp actions. The code will be soon released publicly.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-8">
          <!-- <h2 class="title is-2">Framework</h2> -->
          <h2 class="title is-3 has-text-left">LGGD Framework</h2>
          <figure style="text-align: center;">
            <img id="teaser" height="100%" src="./lggd/LGGD_framework.png" alt="crop_Architecture" style="vertical-align: middle;">
            </figure>
          <div class="content has-text-justified">
            <p>
              The overview of our proposed LGGD framework. Given an RGB image and a natural-language command, a CLIP based image encoder and text encoder extract visual features and word/sentence embeddings. The Dual Cross Vision-Language Fusion (DCVLF) bottleneck aligns the two modalities, after which hierarchical language-guided upsampling progressively refines spatial details according to the textual intent. A coarse mask and grasp prediction head outputs the segmentation mask, grasp quality, angle, and gripper width. Finally, the mask refinement and grasp refinement modules sharpen boundaries and stabilize grasp poses, producing accurate, instruction-consistent grasp poses.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="section results-section">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
  
          <h2 class="title is-3 has-text-left">Results Visualization</h2>
  
          <div class="columns is-centered">
  
            <div class="column">
              <div class="content has-text-centered">
                <h3 class="title is-5 ">Reasoning grasping with key words</h3>
                <!-- <p>Qualitative detection results on RGB images.</p> -->
                <figure class="image">
                  <img src="./lggd/keyword.png" alt="RGB result scene 1">
                </figure>
              </div>
            </div>
  
            <div class="column">
              <div class="content has-text-centered">
                <h3 class="title is-5 ">Reasoning grasping with  descriptions</h3>
                <!-- <p>Qualitative detection results on RGB images.</p> -->
                <figure class="image">
                  <img src="./lggd/descriptions.png" alt="RGB result scene 2">
                </figure>
              </div>
            </div>
  
          </div>


          <div class="columns is-centered">
  
            <div class="column">
              <div class="content has-text-centered">
                <h3 class="title is-5 ">Reasoning grasping with key words</h3>
                <!-- <p>Qualitative detection results on RGB images.</p> -->
                <figure class="image">
                  <img src="./lggd/novel.png" alt="RGB result scene 1">
                </figure>
              </div>
            </div>
  
            <div class="column">
              <div class="content has-text-centered">
                <h3 class="title is-5 ">Reasoning grasping with  descriptions</h3>
                <!-- <p>Qualitative detection results on RGB images.</p> -->
                <figure class="image">
                  <img src="./lggd/location.png" alt="RGB result scene 2">
                </figure>
              </div>
            </div>
  
          </div>
  
        </div>
      </div>
    </div>
  </section>


  <section class="section">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-8">
          <!-- <h2 class="title is-2">Framework</h2> -->
          <h2 class="title is-3 has-text-left">Real-World Interactive Experiments</h2>
          <h3 class="title is-4 has-text-left mt-5">Experiment Setup</h3>
          <figure style="text-align: center;">
            <img id="teaser" height="100%" src="./lggd/real.png" alt="crop_Architecture" style="vertical-align: middle;">
            </figure>
          <div class="content has-text-justified">
            <p>
              We evaluate the proposed system in an interactive grasping setting, where a user issues an instruction specifying a target object and the robot must localize the correct target and execute a pick-and-place operation. Our experiments are conducted on a real robotic platform using a KUKA LBR iiwa 14 R820 manipulator equipped with a Robotiq 2F-85 adaptive gripper. Model inference and the control pipeline are executed on a workstation with an NVIDIA RTX 4090 (24GB) GPU and an AMD Ryzen Threadripper Pro 7955WX CPU.
            </p>
          </div>


          <!-- Results: Different Scene Configurations -->
          <!-- Results: Different Scene Configurations -->
          <h3 class="title is-4 has-text-left mt-6">Results in Different Scene Configurations</h3>

          <!-- Column headers (ONLY ONCE) -->
          <!-- <div class="columns is-centered has-text-centered is-mobile mb-2">
            <div class="column has-text-weight-semibold">Isolated</div>
            <div class="column has-text-weight-semibold">Scattered</div>
            <div class="column has-text-weight-semibold">Cluttered</div>
          </div> -->
          <div class="columns is-centered has-text-centered mb-2">
            <div class="column">
              <p class="title is-5">Isolated</p>
            </div>
            <div class="column">
              <p class="title is-5">Scattered</p>
            </div>
            <div class="column">
              <p class="title is-5">Cluttered</p>
            </div>
          </div>

          <!-- Row 1 -->
          <div class="columns is-centered realworld-videos mb-5">
            <div class="column">
              <video autoplay muted loop playsinline>
                <source src="./lggd/Ball_iso/Ball_iso-1.mp4" type="video/mp4">
              </video>
            </div>
            <div class="column">
              <video autoplay muted loop playsinline>
                <source src="./lggd/ball_sca/ball_sca-1.mp4" type="video/mp4">
              </video>
            </div>
            <div class="column">
              <video autoplay muted loop playsinline>
                <source src="./lggd/ball_clu/ball_clu-1.mp4" type="video/mp4">
              </video>
            </div>
          </div>

          <!-- Row 2 -->
          <div class="columns is-centered realworld-videos mb-5">
            <div class="column">
              <video autoplay muted loop playsinline>
                <source src="./lggd/banana_iso/banana_iso-1.mp4" type="video/mp4">
              </video>
            </div>
            <div class="column">
              <video autoplay muted loop playsinline>
                <source src="./lggd/banana_sca/banana_sca-1.mp4" type="video/mp4">
              </video>
            </div>
            <div class="column">
              <video autoplay muted loop playsinline>
                <source src="./lggd/banana_clu/banana_clu-1.mp4" type="video/mp4">
              </video>
            </div>
          </div>

          <!-- Row 3 -->
          <div class="columns is-centered realworld-videos mb-5">
            <div class="column">
              <video autoplay muted loop playsinline>
                <source src="./lggd/can_iso/can_iso-1.mp4" type="video/mp4">
              </video>
            </div>
            <div class="column">
              <video autoplay muted loop playsinline>
                <source src="./lggd/can_sca/can_sca-1.mp4" type="video/mp4">
              </video>
            </div>
            <div class="column">
              <video autoplay muted loop playsinline>
                <source src="./lggd/can_clu/can_clu-1.mp4" type="video/mp4">
              </video>
            </div>
          </div>

          <!-- Row 4 -->
          <div class="columns is-centered realworld-videos mb-5">
            <div class="column">
              <video autoplay muted loop playsinline>
                <source src="./lggd/glu_iso/glu_iso-1.mp4" type="video/mp4">
              </video>
            </div>
            <div class="column">
              <video autoplay muted loop playsinline>
                <source src="./lggd/glu_sca/glu_sca-1.mp4" type="video/mp4">
              </video>
            </div>
            <div class="column">
              <video autoplay muted loop playsinline>
                <source src="./lggd/glu_clu/glu_clu-1.mp4" type="video/mp4">
              </video>
            </div>
          </div>

        </div>
      </div>
    </div>
  </section>



  <!-- <section class="section">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-7">
            <iframe width="800" height="600"
              src="https://www.youtube.com/embed/V6h1srGtUCY?mute=1">
            </iframe>
            <br>Avoiding lava and mining diamond.
        </div>
      </div>
    </div>
  </section> -->

  <section class="section" id="BibTeX">
    <div class="container content">
      <div class="columns is-centered">
        <div class="column is-two-thirds has-text-justified">
          <h2 class="title">BibTeX</h2>
          <pre><code>@article{jiang2025language,
            title={Language-Guided Grasp Detection with Coarse-to-Fine Learning for Robotic Manipulation},
            author={Jiang, Zebin and Jin, Tianle and Yao, Xiangtong and Knoll, Alois and Cao, Hu},
            journal={arXiv preprint arXiv:2512.21065},
            year={2025}
          }
</code></pre>
        </div>
      </div>
    </div>
  </section>

<!-- <section class="section" id="acknowledgements">
    <div class="container content">
      <div class="columns is-centered">
        <div class="column is-two-thirds has-text-justified">
          <h2 class="title">Acknowledgements</h2>
          <p>Website adapted from the following <a href="http://nerfies.github.io/">template</a>.</p>
        </div>
      </div>
    </div>
  </section> -->

  <p class="is-size-6 has-text-centered">
    Thanks to Keunhong Park for the 
    <a href="http://nerfies.github.io/" target="_blank">website template</a>
    .
  </p>



</body></html>